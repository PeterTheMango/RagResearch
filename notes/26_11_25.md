# Notes of 26/11/2025

Here I planned to recreate the MEMBERSHIP_INFERENCE_ATTACKS_AGAINST_RAGS.pdf environment as well as their attack approach to see how MIA based attacks are done.

Challenges Occured:

- Limited hardware constraints so training time takes much longer.
- Perplexity calculation might be off but the metrics are supporting the results found within the paper.

Insights Found:

- When the generated output we are trying to find within is a member of the knowledgebase, we see scores where BLEU reaches nearer to 100 if its exact.
- PPL also seems to be higher if the generated output is closer to whats found within the knowledgebase.
- The embedding model that is used also matters in the performance of the model.

Next Steps:

- Try to use different LLM models and different embedding models to see how the performance shifts.
- Try to do MASK based MIA Attacks where instead of generating full text, we fill in the blanks of a passage and then compare how close/well the predicted answer is.
